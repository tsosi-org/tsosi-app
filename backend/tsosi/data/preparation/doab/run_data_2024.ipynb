{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1 - Raw file pre-processing\n",
        "\n",
        "- Filter rows corresponding to a transfer, based on whether an amount is present.\n",
        "- Extract only useful columns.\n",
        "- Organize upfront transfers. The data is split per year of support when we want the individual distinct money transfers.\n",
        "- Organize annual & one-year commitment transfers.\n",
        "- Filter out rows corresponding to future transfers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from functools import reduce\n",
        "import re\n",
        "from datetime import date\n",
        "import os\n",
        "import sys\n",
        "import django\n",
        "\n",
        "# Add the parent directory to the system path and setup django\n",
        "BASE_DIR = str(Path(os.getcwd()).resolve().parent.parent.parent.parent)\n",
        "\n",
        "if BASE_DIR not in sys.path:\n",
        "    sys.path.append(BASE_DIR)\n",
        "\n",
        "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"backend_site.settings\")\n",
        "\n",
        "django.setup()\n",
        "\n",
        "from tsosi.data.preparation.cleaning_utils import clean_number_value\n",
        "\n",
        "FILE_INPUT_FOLDER = Path.home() / \"Nextcloud/TSOSI_data/doab/0_raw/\"\n",
        "FILE_OUTPUT_FOLDER = Path.home() / \"Nextcloud/TSOSI_data/doab/1_pre_processed/\"\n",
        "INPUT_NAME = \"2025-02-11-DOAB_Library_Report.xlsx\"\n",
        "# INPUT_NAME = \"2025-02-11-DOAB_Sponsorship_Report.xlsx\"\n",
        "OUTPUT_NAME = f\"{INPUT_NAME.split(\".\")[0]}_pre_processed.xlsx\"\n",
        "\n",
        "AMOUNT_COLS_REGEX = [r\"Annual amount \\(([A-Z]{3})\\)\", r\"Amount \\(([A-Z]{3})\\)\"]\n",
        "amount_columns: dict[str, str] = {}\n",
        "currencies: list[str] = []\n",
        "start_date_col = None\n",
        "end_date_col = None\n",
        "\n",
        "\n",
        "def get_final_cols(df: pd.DataFrame):\n",
        "    compulsory_cols = [\n",
        "        \"Company\",\n",
        "        \"Country\",\n",
        "        \"date_start\",\n",
        "        \"date_end\",\n",
        "        \"Commitment period (years)\",\n",
        "        \"Invoice preference\",\n",
        "    ]\n",
        "    bonus_cols = [\"Supporter type\", \"Agent\", \"Sponsorship level\"]\n",
        "    bonus_cols = [c for c in bonus_cols if c in df.columns]\n",
        "    extra_cols = [f\"amount_{currency}\" for currency in amount_columns.keys()]\n",
        "    return compulsory_cols + extra_cols + bonus_cols\n",
        "\n",
        "\n",
        "def select_transfers(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Filter out rows that do not correspond to a transfer +\n",
        "    clean the amount fields\n",
        "    \"\"\"\n",
        "    compulsory_columns = [\n",
        "        \"Company\",\n",
        "        \"Country\",\n",
        "        *amount_columns.values(),\n",
        "        \"Invoice preference\",\n",
        "        \"Commitment period (years)\",\n",
        "        start_date_col,\n",
        "        end_date_col,\n",
        "    ]\n",
        "\n",
        "    bonus_columns = [\n",
        "        \"Year\",\n",
        "        \"Supporter type\",\n",
        "        \"Agent\",\n",
        "        \"Support confirmation date\",\n",
        "        \"Sponsorship level\",\n",
        "        \"Sponsorship confirmation date\",\n",
        "    ]\n",
        "    bonus_columns = [c for c in bonus_columns if c in df.columns]\n",
        "    useful_columns = compulsory_columns + bonus_columns\n",
        "\n",
        "    amount_mask = None\n",
        "    for col in amount_columns.values():\n",
        "        mask_part = ~df[col].isna()\n",
        "        amount_mask = (\n",
        "            mask_part if amount_mask is None else amount_mask | mask_part\n",
        "        )\n",
        "\n",
        "    date_mask = (~df[start_date_col].isna()) & (~df[end_date_col].isna())\n",
        "    mask = amount_mask & date_mask\n",
        "    df_filtered = df[mask][useful_columns].copy()\n",
        "\n",
        "    print(\n",
        "        f\"Discarded {len(df) - len(df_filtered)} rows without amount \"\n",
        "        f\"out of {len(df)} rows.\"\n",
        "    )\n",
        "\n",
        "    # Clean amount values (some are numbers, other are strings, ...)\n",
        "    def clean_number_error(x):\n",
        "        return clean_number_value(x, False, True)\n",
        "\n",
        "    for col in amount_columns.values():\n",
        "        df_filtered[col] = df_filtered[col].apply(clean_number_error)\n",
        "    return df_filtered\n",
        "\n",
        "\n",
        "def handle_one_year_transfers(transfers: pd.DataFrame):\n",
        "    statuses = [\"one year commitment\", \"annual, one year commitment\"]\n",
        "    one_year = transfers[\n",
        "        transfers[\"Invoice preference\"].str.lower().str.strip().isin(statuses)\n",
        "    ].copy()\n",
        "\n",
        "    one_year[\"_spanned_years\"] = (\n",
        "        one_year[\"_date_end\"].dt.date - one_year[\"_date_start\"].dt.date\n",
        "    ).apply(lambda x: round(x.days / 365))\n",
        "    warning_mask = (one_year[\"Commitment period (years)\"] > 1) | (\n",
        "        one_year[\"_spanned_years\"] > 1\n",
        "    )\n",
        "    warnings = one_year[warning_mask]\n",
        "    if not warnings.empty:\n",
        "        print(\n",
        "            \"The following entities have 'One year commitment' with commitment \"\n",
        "            \"period > 1 year\\n\"\n",
        "            f\"{warnings[\"Company\"].drop_duplicates().to_list()}\\n\"\n",
        "        )\n",
        "\n",
        "    for currency, col in amount_columns.items():\n",
        "        one_year[f\"amount_{currency}\"] = one_year[col]\n",
        "    one_year[\"date_start\"] = one_year[\"_date_start\"]\n",
        "    one_year[\"date_end\"] = one_year[\"_date_end\"]\n",
        "    return one_year[get_final_cols(one_year)].copy()\n",
        "\n",
        "\n",
        "def handle_annual_transfers(transfers: pd.DataFrame):\n",
        "    annuals = transfers[\n",
        "        transfers[\"Invoice preference\"].str.strip().str.lower() == \"annual\"\n",
        "    ].copy()\n",
        "    annuals[\"_spanned_years\"] = (\n",
        "        annuals[\"_date_end\"].dt.date - annuals[\"_date_start\"].dt.date\n",
        "    ).apply(lambda x: max(round(x.days / 365), 1))\n",
        "\n",
        "    # Annual invoice transfers spanning more than 1 year should be split into\n",
        "    # individual years... The raw data is supposed to be this way\n",
        "    # ERRORS - Check the consistency of the commitment period and the support period\n",
        "    error_mask = (annuals[\"_spanned_years\"] > 1) & (\n",
        "        annuals[\"_spanned_years\"] != annuals[\"Commitment period (years)\"]\n",
        "    )\n",
        "    errors = annuals[error_mask]\n",
        "    if not errors.empty:\n",
        "        print(\n",
        "            \"WARNING - The following Entities have Annual transfers spanning \"\n",
        "            \"more than 1 year and inconsistent commitment period:\\n\"\n",
        "            f\"{errors[\"Company\"].drop_duplicates().to_list()}\\n\"\n",
        "        )\n",
        "\n",
        "    to_split_mask = (annuals[\"_spanned_years\"] > 1) & (\n",
        "        annuals[\"_spanned_years\"] == annuals[\"Commitment period (years)\"]\n",
        "    )\n",
        "    to_split = annuals[to_split_mask].copy()\n",
        "\n",
        "    to_split[\"_date_range\"] = to_split.apply(\n",
        "        lambda row: pd.date_range(\n",
        "            row[\"_date_start\"], row[\"_date_end\"], freq=\"YS\", inclusive=\"neither\"\n",
        "        ).append(pd.DatetimeIndex([row[\"_date_start\"]]).sort_values()),\n",
        "        axis=1,\n",
        "    )\n",
        "    splitted = to_split.explode(\"_date_range\")\n",
        "    splitted[\"_date_range_end\"] = splitted[\"_date_range\"].apply(\n",
        "        lambda x: pd.to_datetime(f\"{x.year}-12-31\")\n",
        "    )\n",
        "    splitted[\"date_start\"] = splitted[[\"_date_start\", \"_date_range\"]].max(\n",
        "        axis=1\n",
        "    )\n",
        "    splitted[\"date_end\"] = splitted[[\"_date_end\", \"_date_range_end\"]].min(\n",
        "        axis=1\n",
        "    )\n",
        "    if not to_split.empty:\n",
        "        print(f\"Splitted {len(to_split)} annual transfers.\")\n",
        "\n",
        "    # Group back all Annual invoices\n",
        "    defaults = annuals[~to_split_mask].copy()\n",
        "    defaults[\"date_start\"] = defaults[\"_date_start\"]\n",
        "    defaults[\"date_end\"] = defaults[\"_date_end\"]\n",
        "\n",
        "    annuals_clean = pd.concat([splitted, defaults])\n",
        "    for currency, col in amount_columns.items():\n",
        "        annuals_clean[f\"amount_{currency}\"] = annuals_clean[col]\n",
        "\n",
        "    return annuals_clean[get_final_cols(annuals_clean)].copy()\n",
        "\n",
        "\n",
        "def handle_upfront_transfers(transfers: pd.DataFrame):\n",
        "    # Re-group upfront transfers\n",
        "    upfronts_base = transfers[\n",
        "        transfers[\"Invoice preference\"].str.strip().str.lower() == \"upfront\"\n",
        "    ].copy()\n",
        "    if upfronts_base.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    compulsory_keys = [\n",
        "        \"Company\",\n",
        "        \"Country\",\n",
        "        \"Commitment period (years)\",\n",
        "        *amount_columns.values(),\n",
        "    ]\n",
        "    bonus_keys = [\"Supporter type\", \"Agent\", \"Sponsorship level\"]\n",
        "    bonus_keys = [c for c in bonus_keys if c in transfers.columns]\n",
        "    grouping_keys = compulsory_keys + bonus_keys\n",
        "    grouped = upfronts_base.groupby(grouping_keys, dropna=False)\n",
        "    upfronts = grouped.agg(\n",
        "        date_start=pd.NamedAgg(column=\"_date_start\", aggfunc=\"min\"),\n",
        "        date_end=pd.NamedAgg(column=\"_date_end\", aggfunc=\"max\"),\n",
        "        number=pd.NamedAgg(column=\"_date_start\", aggfunc=\"count\"),\n",
        "    )\n",
        "    upfronts[\"original_ind\"] = grouped.apply(\n",
        "        lambda group: list(group.index), include_groups=False\n",
        "    )\n",
        "    upfronts.reset_index(inplace=True)\n",
        "    upfronts[\"_spanned_years\"] = (\n",
        "        upfronts[\"date_end\"].dt.date - upfronts[\"date_start\"].dt.date\n",
        "    ).apply(lambda x: max(round(x.days / 365), 1))\n",
        "\n",
        "    # ERRORS - These are erroneous according to the discussed model\n",
        "    mask_error = (\n",
        "        upfronts[\"number\"] != upfronts[\"Commitment period (years)\"]\n",
        "    ) | (upfronts[\"_spanned_years\"] != upfronts[\"Commitment period (years)\"])\n",
        "\n",
        "    errors = upfronts[mask_error]\n",
        "    if not errors.empty:\n",
        "        print(\n",
        "            \"ERROR - There are some inconsistent data within the Upfront transfers\\n\"\n",
        "            f\"Check the following entities:\\n{errors[\"Company\"].drop_duplicates().to_list()}\\n\"\n",
        "        )\n",
        "\n",
        "    errors_ind = reduce(\n",
        "        lambda a, b: a + b, errors[\"original_ind\"].to_list(), []\n",
        "    )\n",
        "    upfronts_errors = upfronts_base[upfronts_base.index.isin(errors_ind)].copy()\n",
        "    upfronts_errors[\"date_start\"] = upfronts_errors[\"_date_start\"]\n",
        "    upfronts_errors[\"date_end\"] = upfronts_errors[\"_date_end\"]\n",
        "\n",
        "    for currency, col in amount_columns.items():\n",
        "        upfronts_errors[f\"amount_{currency}\"] = upfronts_errors[col]\n",
        "\n",
        "    # For the remaining groups, the transfers are simply the calculated date start\n",
        "    # & date end and the amount is annual_amount * commitment_years\n",
        "    upfronts_correct = upfronts[~mask_error].copy()\n",
        "    for currency, col in amount_columns.items():\n",
        "        upfronts_correct[f\"amount_{currency}\"] = (\n",
        "            upfronts_correct[col]\n",
        "            * upfronts_correct[\"Commitment period (years)\"]\n",
        "        )\n",
        "\n",
        "    upfronts_correct[\"Invoice preference\"] = \"Upfront\"\n",
        "    if not upfronts_correct.empty:\n",
        "        print(f\"Handled {len(upfronts_correct)} upfront transfers.\")\n",
        "\n",
        "    # Retrieve all data: transformed and untouched erroneous ones\n",
        "    upfronts_clean = pd.concat(\n",
        "        [\n",
        "            upfronts_correct[get_final_cols(upfronts_correct)],\n",
        "            upfronts_errors[get_final_cols(upfronts_errors)],\n",
        "        ]\n",
        "    )\n",
        "    return upfronts_clean\n",
        "\n",
        "\n",
        "def organize_transfers(df: pd.DataFrame):\n",
        "    df[\"_date_start\"] = pd.to_datetime(\n",
        "        df[start_date_col], format=\"%d/%m/%Y\", errors=\"raise\"\n",
        "    )\n",
        "    df[\"_date_end\"] = pd.to_datetime(\n",
        "        df[end_date_col], format=\"%d/%m/%Y\", errors=\"raise\"\n",
        "    )\n",
        "    df[\"_spanned_time\"] = df[\"_date_end\"] - df[\"_date_start\"]\n",
        "\n",
        "    covered_statuses = [\n",
        "        \"annual\",\n",
        "        \"one year commitment\",\n",
        "        \"annual, one year commitment\",\n",
        "        \"upfront\",\n",
        "    ]\n",
        "    non_covered = df[\n",
        "        ~df[\"Invoice preference\"].str.strip().str.lower().isin(covered_statuses)\n",
        "    ]\n",
        "    if not non_covered.empty:\n",
        "        raise Exception(\n",
        "            f\"Unhandled invoice preferences: {non_covered[\"Invoice preference\"].drop_duplicates().to_list()}\"\n",
        "        )\n",
        "\n",
        "    # Split data according to the Invoice preference\n",
        "    res = pd.concat(\n",
        "        [\n",
        "            handle_one_year_transfers(df),\n",
        "            handle_annual_transfers(df),\n",
        "            handle_upfront_transfers(df),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Map amount columns to amount & currency\n",
        "    res[\"amount\"] = None\n",
        "    res[\"currency\"] = None\n",
        "\n",
        "    for c in amount_columns.keys():\n",
        "        col = f\"amount_{c}\"\n",
        "        mask = (~res[col].isna()) & (~res[col].isin([0, \"0\"]))\n",
        "        res.loc[mask, \"currency\"] = c\n",
        "        res.loc[mask, \"amount\"] = res[mask][col]\n",
        "        res.drop(columns=[col], inplace=True)\n",
        "    return res.sort_values([\"Company\", \"date_start\", \"date_end\"])\n",
        "\n",
        "\n",
        "def discard_future_transfers(df: pd.DataFrame):\n",
        "    current_year = date.today().year\n",
        "    mask = df[\"date_start\"] > pd.to_datetime(\n",
        "        f\"{current_year}-07-01\", format=\"%Y-%m-%d\"\n",
        "    )\n",
        "    futures = df[mask]\n",
        "    if not futures.empty:\n",
        "        print(f\"Discarding {len(futures)} future transfers.\")\n",
        "    return df[~mask].copy()\n",
        "\n",
        "\n",
        "def pre_process(export=False):\n",
        "    df = pd.read_excel(f\"{FILE_INPUT_FOLDER}/{INPUT_NAME}\")\n",
        "\n",
        "    # Find correct columns\n",
        "    for regex in AMOUNT_COLS_REGEX:\n",
        "        r = re.compile(regex)\n",
        "        for c in df.columns:\n",
        "            match = r.match(c)\n",
        "            if match:\n",
        "                amount_columns[match.group(1)] = c\n",
        "    start_date_cols = [c for c in df.columns if \"start date\" in c]\n",
        "    if len(start_date_cols) != 1:\n",
        "        raise Exception(f\"Ambiguous start date columns: {start_date_cols}\")\n",
        "    global start_date_col\n",
        "    start_date_col = start_date_cols[0]\n",
        "    end_date_cols = [c for c in df.columns if \"end date\" in c]\n",
        "    if len(end_date_cols) != 1:\n",
        "        raise Exception(f\"Ambiguous end date columns: {end_date_cols}\")\n",
        "    global end_date_col\n",
        "    end_date_col = end_date_cols[0]\n",
        "    if \"Invoice preferences\" in df.columns:\n",
        "        df.rename(\n",
        "            columns={\"Invoice preferences\": \"Invoice preference\"}, inplace=True\n",
        "        )\n",
        "\n",
        "    df_filtered = select_transfers(df)\n",
        "    df_clean = organize_transfers(df_filtered)\n",
        "    df_final = discard_future_transfers(df_clean)\n",
        "    df_final[\"date_start\"] = df_final[\"date_start\"].dt.date\n",
        "    df_final[\"date_end\"] = df_final[\"date_end\"].dt.date\n",
        "    if export:\n",
        "        df_final.to_excel(\n",
        "            f\"{FILE_OUTPUT_FOLDER}/{OUTPUT_NAME}\",\n",
        "            sheet_name=\"Transfers\",\n",
        "            index=False,\n",
        "        )\n",
        "    return df_final\n",
        "\n",
        "\n",
        "res = pre_process(export=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# res.to_excel(\n",
        "#     \"/home/guillaume-alzieu/Nextcloud/TSOSI_data/doab/temp_correction.xlsx\",\n",
        "#     index=False,\n",
        "# )\n",
        "res.sort_values(\"amount\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 - Pre-processed data -> ROR matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import django\n",
        "import pandas as pd\n",
        "from asgiref.sync import sync_to_async\n",
        "\n",
        "# Add the parent directory to the system path and setup django\n",
        "BASE_DIR = str(Path(os.getcwd()).resolve().parent.parent.parent.parent)\n",
        "\n",
        "if BASE_DIR not in sys.path:\n",
        "    sys.path.append(BASE_DIR)\n",
        "\n",
        "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"backend_site.settings\")\n",
        "\n",
        "django.setup()\n",
        "\n",
        "from tsosi.data.pid_matching import prepare_manual_matching\n",
        "\n",
        "\n",
        "file_folder = Path.home() / \"Nextcloud/TSOSI_data/doab/1_pre_processed/\"\n",
        "INPUT_NAME = \"2025-02-11-DOAB_Sponsorship_Report_pre_processed.xlsx\"\n",
        "sheet = \"Transfers\"\n",
        "name_column = \"Company\"\n",
        "country_colum = \"Country\"\n",
        "\n",
        "\n",
        "@sync_to_async\n",
        "def to_run():\n",
        "    xls = pd.ExcelFile(str(file_folder / INPUT_NAME))\n",
        "    data = pd.read_excel(xls, sheet)\n",
        "    return prepare_manual_matching(\n",
        "        data, name_column, country_column=country_colum\n",
        "    )\n",
        "\n",
        "\n",
        "res = await to_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_folder = Path.home() / \"Nextcloud/TSOSI_data/doab/2_matched/\"\n",
        "OUTPUT_NAME = \"2025-02-11-DOAB_Sponsorship_Report_matched.xlsx\"\n",
        "res.to_excel(str(export_folder / OUTPUT_NAME), sheet_name=sheet, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res[~res[\"Agent\"].isna()][[\"Agent\", \"Country\"]].drop_duplicates(\n",
        "    [\"Agent\", \"Country\"]\n",
        ").sort_values(\"Agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4 - Prepare enriched data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import django\n",
        "import pandas as pd\n",
        "\n",
        "# Add the parent directory to the system path and setup django\n",
        "BASE_DIR = str(Path(os.getcwd()).resolve().parent.parent.parent.parent)\n",
        "\n",
        "if BASE_DIR not in sys.path:\n",
        "    sys.path.append(BASE_DIR)\n",
        "\n",
        "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"backend_site.settings\")\n",
        "\n",
        "django.setup()\n",
        "\n",
        "from tsosi.data.utils import clean_null_values\n",
        "from tsosi.data.preparation.cleaning_utils import clean_cell_value\n",
        "from tsosi.data.pid_matching import process_enriched_data\n",
        "from tsosi.models.transfer import (\n",
        "    TRANSFER_ENTITY_TYPE_EMITTER,\n",
        "    TRANSFER_ENTITY_TYPE_AGENT,\n",
        ")\n",
        "\n",
        "file_folder = Path.home() / \"Nextcloud/TSOSI_data/doab/\"\n",
        "file_base_name = \"2025-02-11-DOAB_Library_Report\"\n",
        "INPUT_NAME = f\"3_enriched/{file_base_name}_enriched.xlsx\"\n",
        "sheet_transfers = \"Transfers\"\n",
        "name_col = \"Company\"\n",
        "\n",
        "\n",
        "def process(process_agents=False):\n",
        "    xls = pd.ExcelFile(str(file_folder / INPUT_NAME))\n",
        "    data = pd.read_excel(xls, sheet_transfers)\n",
        "    # Process enriched emitter data\n",
        "    res = process_enriched_data(data, name_col, TRANSFER_ENTITY_TYPE_EMITTER)\n",
        "\n",
        "    if process_agents:\n",
        "        # Process enriched agents data\n",
        "        sheet_agent = \"Consortiums\"\n",
        "        agent_col = \"Agent\"\n",
        "        country_col = \"Country\"\n",
        "        agents = pd.read_excel(xls, sheet_agent)\n",
        "        for col in [agent_col, country_col]:\n",
        "            res[col] = res[col].apply(clean_cell_value)\n",
        "            agents[col] = agents[col].apply(clean_cell_value)\n",
        "        # MAKE SURE THERE ARE NO DUPLICATES IN AGENT TO NOT CREATE TRANSFERS\n",
        "        # WHEN LEFT JOINING\n",
        "        agents.drop_duplicates(subset=[agent_col, country_col], inplace=True)\n",
        "        clean_null_values(agents)\n",
        "        clean_null_values(res)\n",
        "        agents[\"_merged_from_agent\"] = True\n",
        "        res = res.merge(agents, on=[agent_col, country_col], how=\"left\")\n",
        "        # Check that all agents\n",
        "        mask = ~res[agent_col].isna() & (res[\"_merged_from_agent\"] != True)\n",
        "        errors = res[mask]\n",
        "        if not errors.empty:\n",
        "            print(f\"Error with agent handling, check return.\")\n",
        "            return errors\n",
        "        res.drop(columns=[\"_merged_from_agent\"], inplace=True)\n",
        "\n",
        "        res = process_enriched_data(res, agent_col, TRANSFER_ENTITY_TYPE_AGENT)\n",
        "\n",
        "    clean_null_values(res)\n",
        "    res[\"date_start\"] = res[\"date_start\"].dt.date\n",
        "    res[\"date_end\"] = res[\"date_end\"].dt.date\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "res = process(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prepared_file_path = (\n",
        "    file_folder / \"4_prepared\" / f\"{file_base_name}_prepared.xlsx\"\n",
        ")\n",
        "\n",
        "res.to_excel(str(prepared_file_path), sheet_name=\"Transfers\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5 - Generate TSOSI data file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import django\n",
        "from datetime import date\n",
        "\n",
        "# Add the parent directory to the system path and setup django\n",
        "BASE_DIR = str(Path(os.getcwd()).resolve().parent.parent.parent.parent)\n",
        "\n",
        "if BASE_DIR not in sys.path:\n",
        "    sys.path.append(BASE_DIR)\n",
        "\n",
        "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"backend_site.settings\")\n",
        "\n",
        "django.setup()\n",
        "\n",
        "from tsosi.data.preparation.doab.libraries import get_config as config_libraries\n",
        "from tsosi.data.preparation.doab.sponsors import get_config as config_sponsors\n",
        "\n",
        "date_data = date(2025, 2, 11)\n",
        "# Libraries\n",
        "file_path = (\n",
        "    Path.home()\n",
        "    / \"Nextcloud/TSOSI_data/doab/4_prepared/2025-02-11-DOAB_Library_Report_prepared.xlsx\"\n",
        ")\n",
        "sheet_name = \"Transfers\"\n",
        "config = config_libraries(str(file_path), sheet_name, date_data)\n",
        "config.generate_data_file()\n",
        "\n",
        "# Sponsors\n",
        "file_path = (\n",
        "    Path.home()\n",
        "    / \"Nextcloud/TSOSI_data/doab/4_prepared/2025-02-11-DOAB_Sponsorship_Report_prepared.xlsx\"\n",
        ")\n",
        "sheet_name = \"Transfers\"\n",
        "config = config_sponsors(str(file_path), sheet_name, date_data)\n",
        "config.generate_data_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use already performed matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Map with previous matching\n",
        "from pathlib import Path\n",
        "\n",
        "file = (\n",
        "    Path.home()\n",
        "    / \"Nextcloud/TSOSI_data/doab/2_matched\"\n",
        "    / \"2025-02-11-DOAB_Library_Report_matched.xlsx\"\n",
        ")\n",
        "matched = pd.read_excel(file)\n",
        "matching_columns = [c for c in matched.columns if c.startswith(\"_\")]\n",
        "data = (\n",
        "    matched.groupby([\"Company\", \"Country\"], dropna=False)[matching_columns]\n",
        "    .first()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "organized = res.merge(data, how=\"left\", on=[\"Company\", \"Country\"])\n",
        "sorted_cols = []\n",
        "for c in organized.columns:\n",
        "    if c in matching_columns:\n",
        "        continue\n",
        "    sorted_cols.append(c)\n",
        "    if c == \"Company\":\n",
        "        sorted_cols += matching_columns\n",
        "\n",
        "organized[sorted_cols]\n",
        "organized[\"_processed\"] = organized[\"_processed\"].apply(\n",
        "    lambda x: x if pd.isna(x) else True\n",
        ")\n",
        "organized[sorted_cols].to_excel(\n",
        "    Path.home()\n",
        "    / \"Nextcloud/TSOSI_data/doab/2_matched\"\n",
        "    / \"2025-02-11-DOAB_Library_Report_matched_grouped.xlsx\",\n",
        "    index=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use already enriched data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "to_enrich_file = Path.home() / \"Nextcloud/TSOSI_data/doab/temp_correction.xlsx\"\n",
        "enriched_file = (\n",
        "    Path.home()\n",
        "    / \"Nextcloud/TSOSI_data/doab/3_enriched/2025-02-11-DOAB_Library_Report_enriched_backup.xlsx\"\n",
        ")\n",
        "\n",
        "to_enrich = pd.read_excel(str(to_enrich_file))\n",
        "enriched = pd.read_excel(str(enriched_file), sheet_name=\"Transfers\")\n",
        "consortiums = pd.read_excel(str(enriched_file), sheet_name=\"Consortiums\")\n",
        "\n",
        "enrichment_columns = [c for c in enriched.columns if c.startswith(\"_\")]\n",
        "data = (\n",
        "    enriched.groupby([\"Company\", \"Country\"], dropna=False)[enrichment_columns]\n",
        "    .first()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "organized = to_enrich.merge(data, how=\"left\", on=[\"Company\", \"Country\"])\n",
        "sorted_cols = []\n",
        "for c in organized.columns:\n",
        "    if c in enrichment_columns:\n",
        "        continue\n",
        "    sorted_cols.append(c)\n",
        "    if c == \"Company\":\n",
        "        sorted_cols += enrichment_columns\n",
        "\n",
        "organized = organized[sorted_cols].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_file = (\n",
        "    Path.home()\n",
        "    / \"Nextcloud/TSOSI_data/doab/3_enriched/2025-02-11-DOAB_Library_Report_enriched.xlsx\"\n",
        ")\n",
        "writer = pd.ExcelWriter(str(output_file), engine=\"xlsxwriter\")\n",
        "organized.to_excel(writer, sheet_name=\"Transfers\", index=False)\n",
        "consortiums.to_excel(writer, sheet_name=\"Consortiums\", index=False)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consortiums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bonus check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for overlapping periods\n",
        "columns = [\n",
        "    \"Company\",\n",
        "    \"_date_start\",\n",
        "    \"_date_end\",\n",
        "    \"Country\",\n",
        "    \"Agent\",\n",
        "]\n",
        "d = res[columns].copy(deep=True)\n",
        "\n",
        "d[\"_date_range\"] = d.apply(\n",
        "    lambda row: pd.date_range(row[\"_date_start\"], row[\"_date_end\"]),\n",
        "    axis=1,\n",
        ")\n",
        "d = d.explode(\"_date_range\")\n",
        "d[d[[\"Company\", \"_date_range\"]].duplicated()][\"Company\"].unique()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
